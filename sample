Qs: What is the bias-variance tradeoff in machine learning?
Answer:
Balancing underfitting (high bias==big assumption like linear model) and overfitting (high variance) to achieve optimal model performance.


Qs: In case we have a high variance in a model, what does it mean? how to midigate it?
Answer:
High variance means the model overfits the training data and performs poorly on new data.
Mitigation: Use regularization, simplify the model, or add more training data.

Qs: What is the impact of sample size (increasing or decreasing data) on variance? what about the impact on bias?
Increasing data: Reduces variance by improving generalization.
Decreasing data: Increases variance, making the model unstable.
Bias: Unaffected significantly by sample size unless the data is highly unrepresentative.

Qs: How do you see the association of linear model vs. NN on the bias?
Linear models: Big assumption, Higher bias, as they assume a linear relationship.
Neural networks: Lower bias due to flexibility but prone to higher variance.


**************************************************************************
Task: Model evaluation
Bank customers can report a transaction invalid or unauthorized and request a refund from their bank.
Depending on situation, the refund either will be approved or not.
Assume we have access to some sort of customer details, transaction data, bank records, seller(merchant) history and we built a machine learning model to predict whether a refund will be approved. Your task is to evaluate the performance of this model.

Qs: What metrics would you use to evaluate the model's performance in predicting refunds? A) in case we have 65% approved, B) in case we have 90% approve?
1. Evaluation Metrics:
A) 65% approved: Use F1-score for a balanced view of precision and recall. AUC-ROC to evaluate discrimination across thresholds.
B) 90% approved: Focus on recall to minimize missed refunds and monitor precision to avoid too many false positives.


QS: How would you ensure there is no data leakage during the training process?
2. Preventing Data Leakage:
Ensure no future-related information (e.g., refund decisions or communication outcomes) is in training data.
Avoid derived features that include post-decision knowledge.
Verify feature sources to ensure no outcome-related data sneaks in.


Qs: How do you ensure the model remains up-to-date and performs well over time?
3. Model Freshness:
Track key metrics (precision, recall) over time on recent data.
Use drift detection to monitor changes in feature distributions.
Retrain when performance degrades or data distributions change significantly.

Qs: If the product manager asks whether additional data is needed for model training, how do you determine your answer
Analyze learning curves to check if performance improves with more data.
Identify segments with poor performance (e.g., new merchants or dispute types) to detect gaps.
High variance suggests that more data may help stabilize the model.

*********************************************************************

When we make a transaction, each one has a short description that appears on our bank statement. For example, instead of showing 'Uber,' the statement might show something like 'UBERTRIP12345,' which can be unclear to customers and a source of confusion for the customer.
As an example:


UBER*TRIP12345 - Uber
AMZN Mktp CAN*LJ3B76 - Amazon Marketplace
1230345CAD STARB- TORONTO - Starbucks
NETFLIX.COM 39420 - Netflix
#4512 WALMART SUPERCNT  - Walmart
PAYPAL*12 *SHOPONLINE - PayPal
EAT LYFT *RIDE6789 - Lyft
APPLE.COM/BILL - Apple


How would you design a solution to match these unclear transaction descriptions to the correct merchant names? 
Walk me through your approach, covering data preparation, model selection, handling tricky cases, and evaluating performance."*

How would you handle new or unseen descriptors?
How would you measure model's accuracy?
What are the pros and cons of using rule-based vs. machine learning approaches?
Do you think Gen AI can be a good option?
Any preference in terms of which LLM model to use?
What concideration you take in case of usign LLM?
How would you make the system scalable for millions of transactions?


Solution Design for Matching Transaction Descriptors to Merchant Names:
Data Collection and Preparation:

Collect transaction descriptions, merchant names, and relevant metadata (e.g., location, transaction type).
Preprocess the text: remove special characters, lowercase, and tokenize for consistency.
Baseline Approach:

Implement a fuzzy matching algorithm (e.g., Levenshtein distance) to match similar descriptors.
Use regex patterns to identify common descriptor structures (e.g., remove IDs or prefixes like "UBERTRIP").
ML-Based Approach:

Train a classification model (e.g., SVM, logistic regression) or NLP-based model to predict the correct merchant based on the descriptor.
Alternatively, use embedding models (e.g., BERT embeddings) to compute the similarity between descriptor and merchant names.
Handling New or Unseen Descriptors:
Use semantic embeddings to find the most similar descriptors from known merchants.
Implement a fallback rule-based approach for unseen descriptors or flag them for manual review.
Regularly retrain the model with new descriptor-merchant pairs.
Measuring Model Accuracy:
Use standard metrics like accuracy, precision, recall, and F1-score for classification tasks.
Measure top-N accuracy if the system suggests multiple possible matches.
Perform manual spot checks for ambiguous cases.
Rule-Based vs. Machine Learning Approach:
Rule-Based:
Pros: Easy to implement, interpretable, and effective for simple cases.
Cons: Hard to maintain and scale, brittle with unseen patterns.
ML-Based:
Pros: Handles complex descriptors, adapts to new patterns, and scalable with retraining.
Cons: Requires more data and monitoring; harder to explain decisions.
Use of Generative AI (Gen AI):
Gen AI (e.g., GPT models) can generate meaningful mappings between descriptors and merchant names, especially in ambiguous cases.
It can also assist in expanding rule-based systems by suggesting patterns or categories of descriptors.
LLM Model Preferences:
OpenAI GPT-4/Claude/BERT: If interpretability and generalization are critical.
Domain-Specific LLMs (FinBERT): If financial terminology is important.
Considerations When Using LLMs:
Cost: LLMs can be expensive for high-volume data processing.
Latency: Ensure response times are acceptable for real-time systems.
Privacy: Ensure sensitive financial data is anonymized when using external APIs.
Fine-Tuning: Consider fine-tuning an LLM with your dataset for improved accuracy on domain-specific terms.
Scalability for Millions of Transactions:
Use batch processing with parallelization for large datasets.
Implement vector databases (e.g., FAISS) for efficient similarity searches.
Deploy a hybrid system: fast rule-based matching for common cases and ML/LLM models for complex cases.
Use caching to store frequent descriptor-merchant pairs to avoid redundant computations.
